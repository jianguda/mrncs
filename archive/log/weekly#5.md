## DONE
In this week (Week#5),
- For experiments: setted up the environment and tried the training of a tiny model (also submitted initial results). started checking baseline models. tested tree-sitter in generating ast data.
- For exploration: checked latest papers, such as SLM, and one survey paper on program modeling. studied graph embedding. read some materials on graph2seq.

## NEXT-STEPS
In next week (Week#6), for baseline models, I will try to add the AST modality to the existing token modality. For AST modality, the MMAN paper uses Tree-LSTM, I plan to explore the path manner taken by code2seq in preserving info because I feel it seems simpler. I will generate ast data for the Python dataset firstly and choose one given baseline model to conduct early experiments. Besides, I plan to spend about two or three days on writting the thesis draft.

## QUESTIONS
I met strange issues in setting up the environment but finally have successfully fixed or avoided them. There are no other questions because I am in the early stage in my practical work.

## Special Note
Because the master thesis draft is required in some PhD applications, so I plan to in advance write the first three chapters (introduction, background, related work) and few sections of the fourth chapter (methodology).