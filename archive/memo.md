### Natural Language
- [`Sequence to Sequence Learning with Neural Networks`](https://arxiv.org/abs/1409.3215)
- [`GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding`](https://arxiv.org/abs/1804.07461)
- https://nlp.stanford.edu/~johnhew/structural-probe.html
#### Survey
- [`Recent Trends in Deep Learning Based Natural Language Processing`](https://arxiv.org/abs/1708.02709)
- [`A Survey of the Usages of Deep Learning in Natural Language Processing`](https://arxiv.org/abs/1807.10854)
- https://zhuanlan.zhihu.com/p/57979184
- https://nlpoverview.com/
- https://github.com/omarsar/nlp_overview
#### Word2Vec
- [`Distributed Representations of Words and Phrases and their Compositionality`](https://arxiv.org/abs/1310.4546)
- [`Glove: Global Vectors for Word Representation`](https://www.aclweb.org/anthology/D14-1162/)
- [`Enriching Word Vectors with Subword Information`](https://arxiv.org/abs/1607.04606)
- _[`Efficient Estimation of Word Representations in Vector Space`](https://arxiv.org/abs/1301.3781)_
- _[`Augmenting Self-attention with Persistent Memory`](https://arxiv.org/abs/1907.01470)_
#### CNN
- [`Convolutional Neural Networks for Sentence Classification`](https://arxiv.org/abs/1408.5882)
#### RNN
- [`Finding Structure in Time`](https://crl.ucsd.edu/~elman/Papers/fsit.pdf)
- [`Long Short-Term Memory`](https://www.bioinf.jku.at/publications/older/2604.pdf)
- [`Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation`](https://arxiv.org/abs/1406.1078)
#### GNN
- [`A new model for learning in graph domains`](https://ieeexplore.ieee.org/document/1555942)
- [`The Graph Neural Network Model`](https://ieeexplore.ieee.org/document/4700287)
- https://zhuanlan.zhihu.com/weichennote
- https://github.com/thunlp/GNNPapers
#### Attention
- [`Attention Is All You Need`](https://arxiv.org/abs/1706.03762)
- [`Universal Transformers`](https://arxiv.org/abs/1807.03819)
- [`Transformer-XL: Attentive Language Models Beyond a Fixed-Length Context`](https://arxiv.org/abs/1901.02860)
- [`Reformer: The Efficient Transformer`](https://arxiv.org/abs/2001.04451)
- _[`Attention is not not Explanation`](https://arxiv.org/abs/1908.04626)_
- _[`Attention Augmented Convolutional Networks`](https://arxiv.org/abs/1904.09925)_
- _[`Compressive Transformers for Long-Range Sequence Modelling`](https://arxiv.org/abs/1911.05507)_
- [`Deep contextualized word representations`](https://arxiv.org/abs/1802.05365)
- [`Improving Language Understanding by Generative Pre-Training`](https://openai.com/blog/language-unsupervised/)
- [`Better Language Models and Their Implications`](https://openai.com/blog/better-language-models/)
- [`BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding`](https://arxiv.org/abs/1810.04805)
- [`XLNet: Generalized Autoregressive Pretraining for Language Understanding`](https://arxiv.org/abs/1906.08237)
- https://jalammar.github.io/illustrated-bert/
- https://jalammar.github.io/illustrated-gpt2/
- http://jalammar.github.io/a-visual-guide-to-using-bert-for-the-first-time/
- http://colah.github.io/posts/2015-08-Understanding-LSTMs/
- https://towardsdatascience.com/understanding-gru-networks-2ef37df6c9be
- http://www.peterbloem.nl/blog/transformers
- https://jalammar.github.io/illustrated-transformer/
- https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3
- https://mp.weixin.qq.com/s/Rn3yZ2lg5JuntTD3ka7Kfw

### Program Code
- _[`Neural Code Search Evaluation Dataset`](https://arxiv.org/abs/1908.09804)_
- https://github.com/src-d/awesome-machine-learning-on-source-code
#### Survey
- [`Deep Learning for Source Code Modeling and Generation: Models, Applications and Challenges`](https://arxiv.org/abs/2002.05442)
- _[`A Literature Study of Embeddings on Source Code`](https://arxiv.org/abs/1904.03061)_
- _[`Comparison of Syntactic and Semantic Representations of Programs in Neural Embeddings`](https://arxiv.org/abs/2001.09201)_
#### Program Representation
- [`Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks`](https://arxiv.org/abs/1503.00075)
- _[`Modeling Programs Hierarchically with Stack-Augmented LSTM`](https://arxiv.org/abs/2002.04516)_
- [`Gated Graph Sequence Neural Networks`](https://arxiv.org/abs/1511.05493)
- [`Learning to Represent Programs with Graphs`](https://arxiv.org/abs/1711.00740)
- _[`GLOBAL RELATIONAL MODELS OF SOURCE CODE`](https://openreview.net/pdf?id=B1lnbRNtwr)_
- [`Multi-Modal Attention Network Learning for Semantic Source Code Retrieval`](https://arxiv.org/abs/1909.13516)
- [`A General Path-Based Representation for Predicting Program Properties`](https://arxiv.org/abs/1803.09544)
- [`code2vec: Learning Distributed Representations of Code`](https://arxiv.org/abs/1803.09473)
- [`code2seq: Generating Sequences from Structured Representations of Code`](https://arxiv.org/abs/1808.01400)
- [`Structural Language Models of Code`](https://arxiv.org/abs/1910.00577)
- [`Learning Scalable and Precise Representation of Program Semantics`](https://arxiv.org/abs/1905.05251)
- [`Learning Blended, Precise Semantic Program Embeddings`](https://arxiv.org/abs/1907.02136)
- [`CodeBERT: A Pre-Trained Model for Programming and Natural Languages`](https://arxiv.org/abs/2002.08155)
- [`Aroma: code recommendation via structural code search`](https://arxiv.org/abs/1812.01158)
- https://mp.weixin.qq.com/s/PZ0I_I1-1MaR7dbhzVCBAw
- https://ai.facebook.com/blog/aroma-ml-for-code-recommendation/
#### Code Searching
- [`An Introduction to Neural Information Retrieval`](https://ieeexplore.ieee.org/document/8620670)
- [`Retrieval on source code: a neural code search`](https://people.eecs.berkeley.edu/~ksen/papers/ncs.pdf)
- [`Deep Code Search`](https://ieeexplore.ieee.org/document/8453172)
- [`CodeSearchNet Challenge: Evaluating the State of Semantic Code Search`](https://arxiv.org/abs/1909.09436)
- [`When Deep Learning Met Code Search`](https://arxiv.org/abs/1905.03813)
- [`Signature Verification Using A "Siamese" Time Delay Neural Network`](https://papers.nips.cc/paper/769-signature-verification-using-a-siamese-time-delay-neural-network.pdf)
- _[`Neural Network-based Graph Embedding for Cross-Platform Binary Code Similarity Detection`](https://arxiv.org/abs/1708.06525)_
- _[`Neural Machine Translation Inspired Binary Code Similarity Comparison beyond Function Pairs`](https://arxiv.org/abs/1808.04706)_
- _[`Learning-Based Recursive Aggregation of Abstract Syntax Trees for Code Clone Detection`](https://ieeexplore.ieee.org/document/8668039)_
