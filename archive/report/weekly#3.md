## DONE
In this week (Week#3), I have studied most of collected papers. These papers are in few types: 1) Surveys, 2) NLP-related, 3) Code-related, 4) Theories.

I fully studied papers of the first type, they are mainly about 1) Cross-lingual Word Embedding Models, 2) Embeddings on Source Code, 3) Deep Learning in Natural Language Processing.

I briefly studied classic papers of NLP models, such as word2vec, BERT, GPT-2, XLNet, etc. I also read blogs to help understand their feature extractors.

For the Code-related papers, I read some inspiring papers, such as code2seq, code2vec, GGNN, MMAN, etc. Besides, I also read some papers about code search models, namely NCS, UNIF, CODEnn, SCS.

For papers about theories, I mainly read some on attention. I also slightly checked some papers about GNN.

## NEXT-STEPS
In next week (Week#4), I will firstly prepare the experiment environment, to reproduce baseline models. Based on that, I will determine my work. Meanwhile, I am going to carefully study direcly helpful papers, as well as write related chapters for my thesis report.

## QUESTIONS
I am still studying papers and considering possible works. I have no questions for the time being.

## Special Note
In my preliminary project plan, pre-study period would take 5 weeks. I decide to shorten it to 4 weeks.
